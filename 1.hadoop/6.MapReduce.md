# MapReduce

##### 1. MapReduce 的工作机制

MapReduce 作业提交流程如图

- **MapReduce 工作流程**

![Hadoop架构图-Yarn 工作流程](D:/note/hadoop/Hadoop%E6%9E%B6%E6%9E%84%E5%9B%BE-Yarn%20%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B-1620216024033.png)

当用户向 Yarn 中提交一个应用程序后, YARN 将分为两个阶段运行该应用程序:

- 第一阶段

    启动 ApplicationMaster

- 第二阶段

    由 ApplicationMaster 创建应用程序, 为它申请资源, 并监控它的整个运行过程, 直到运行完成.

Yarn 的工作流程

1. 用户向 Yarn 中提交应用程序, 其中包括 ApplicationMaster 程序, 启动 ApplicationMaster 的命令, 用户程序等.

    - 作业 Jar 文件
    - 配置文件
    - 计算所得的输入分片

2. ResourceManager 为该应用程序分配第一个 Container, 并与对应的 NodeManager 通信, 要求它在整个 Container 中启动应用程序的 ApplicationMaster

3. ApplicationMaster 首先向 ResourceManager 注册, 这样用户可以直接通过 ResourceManager 查看应用程序的运行状态, 然后它将为各个任务申请资源,并监控它的运行状态,直到运行结束.

    **mapreduce.job.ubertask.maxmaps**

    **mapreduce.job.ubertask.maxreduces**

    **mapreduce.job.ubertask.maxbytes**

    **mapreduce.job.ubertask.enable**

    

4. ApplicationMaster 采用轮询的方式通过 RPC 协议向 ResourceManager 申请和领取资源

5. ApplicationMaster 申请到资源后,便与对应的 NodeManager 通信, 要求它启动任务

6. NodeManager 为任务设置好运行环境 (包括环境变量, JAR 包, 二进制程序等)后, 将任务启动命令写到一个脚本中,并通过运行该脚本启动任务

    reduce 任务能够在集群中任意位置运行,但是 map 任务的请求有着数据本地化的局限, 理想情况下, 任务在数据分片所在节点执行.

    mapreduce.map.memory.mb

    mapreduce.reduce.memory.mb

    mapreduce.map.cpu.vcores

    mapreduce.reduce.cpu.vcores.memory.mb

    

7. 各个任务通过某个 RPC 协议向 ApplicationMaster 汇报自己的状态和进度, 以让 ApplicationMaster 随时掌握各个任务的运行状态,从而可以在任务失败时重新启动任务

8. 应用程序运行完成之后, ApplicationMaster 向 ResourceManager 注销并关闭自己.



##### 2. 作业失败

1. 任务运行失败

- map 任务或者 reduce 任务中的用户代码抛出异常导致失败. applications master 会将此次任务标记为失败,并释放容器资源给其它任务使用
- 任务 JVM 突然退出. 这种情况下, NodeManager 会注意到进程已经退出, 并通知 application master 将此次任务标记为失败
- 任务挂起.  application master 标记为任务失败, 并 kill 任务

application master 被告知一个任务尝试失败后, 将重新调度该任务的执行. application master 会试图避免在以前失败过的 NodeManager 上重新调度该任务.

任务重试参数配置

**mapreduce.map.maxattempt**

**mapreduce.reduce.maxattempt**



2. application master 运行失败

Yarn 中的应用程序在运行失败时也会进行重试, 由 mapreduce.am.max-attempts 属性控制, 默认2次. 失败两次后, 便不会进行重新.

Yarn 集群上也会进行控制, yarn.resourcemanager.am.max-attempts 属性设置, 默认是 2.

application master 恢复的过程如下.

application master 向 resource manager 发送周期性心跳, 当 application master 失败时, resource manager 会检测到该失败并在一个新的容器 (由 node manager 管理) 中开始一个新的 master 实例. 对于 mapreduce application master, 它将使用作业历史来恢复失败的应用程序所运行任务的状态, 使其不必重新运行. 默认情况下恢复功能是开启的, 但可以通过设置 yarn.app.mapreduce.am.job.recovery.enable 为 false 关闭这个功能.



3. 节点管理器运行失败 (NodeManager)

如果 node manager 由崩溃或者运行非常缓慢而失败, 就会停止向 resource manager 发送心跳信息, 如果 10 分钟内没有收到一条心跳信息  resource manager 将会通知停止发送心跳信息的 node manager, 并将其从自己的节点池中移除以调度启用容器

**yarn.resourcemanager.nm.liveness-monitor.expiry-interval-ms**

在失败的 node manager 运行的任务或者 application master 会被重新调度到其它节点.



4. 资源管理器运行失败

resource manager 失败会进行故障转移, 主备切换.

resource manager 从备节点切换到主节点是有故障转移控制器处理的. 默认的故障转移控制器是自动工作的, 使用 zookeeper 的 leader 选举机制 (leader election) 以确保同一时刻自由一个主 resource manager.



##### 3. shuffle 和排序

MapReduce 确保每个 reducer 的输入都是按键排序的. 系统执行排序, 将 map 输出作为输入传给 reducer 的过程称为 shuffle.

![Hadoop架构图-MapReduce 作业执行过程](D:/note/hadoop/Hadoop%E6%9E%B6%E6%9E%84%E5%9B%BE-MapReduce%20%E4%BD%9C%E4%B8%9A%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B.png)

**MapTask流程**

1. 首先，读取数据组件InputFormat（默认TextInputFormat）会通过getSplits方法对输入目录中文件进行逻辑切片规划得到splits，有多少个split就对应启动多少个MapTask。split与block的对应关系默认是一对一。

2. 将输入文件切分为splits之后，由RecordReader对象（默认LineRecordReader）进行读取，以\n作为分隔符，读取一行数据，返回<key，value>。Key表示每行首字符偏移值，value表示这一行文本内容。

    ```
    运行作业的客户端通过调用 getSplits() 计算分片, 然后将它们发送到 application master, application master 使用其存储位置信息来调度 map 任务从而在集群上处理这些分片数据. map 任务把输入任务分片给 InputFormat 的 createRecordReader() 方法来获得这个分片的 RecordReader.
    RecordReader 就像是记录上的迭代器, map 任务用一个 RecordReader 来生成记录的键值对, 然后再传递给 map 函数.
    ```

3. 读取split返回<key,value>，进入用户自己继承的Mapper类中，执行用户重写的map函数。RecordReader读取一行这里调用一次。

4. map逻辑完之后，将map的每条结果通过context.write进行collect数据收集。在collect中，会先对其进行分区处理，默认使用HashPartitioner。

  **MapReduce提供Partitioner接口，它的作用就是根据key或value及reduce的数量来决定当前的这对输出数据最终应该交由哪个reduce task处理。默认对key hash后再以reduce task数量取模。默认的取模方式只是为了平均reduce的处理能力，如果用户自己对Partitioner有需求，可以订制并设置到job上。**

5. 接下来，会将数据写入内存，内存中这片区域叫做环形缓冲区，缓冲区的作用是批量收集map结果，减少磁盘IO的影响。我们的key/value对以及Partition的结果都会被写入缓冲区。当然写入之前，key与value值都会被序列化成字节数组。

  - 环形缓冲区其实是一个数组，数组中存放着key、value的序列化数据和key、value的元数据信息，包括partition、key的起始位置、value的起始位置以及value的长度。环形结构是一个抽象概念。
  - 缓冲区是有大小限制，默认是100MB。当map task的输出结果很多时，就可能会撑爆内存，所以需要在一定条件下将缓冲区中的数据临时写入磁盘，然后重新利用这块缓冲区。这个从内存往磁盘写数据的过程被称为Spill，中文可译为溢写。这个溢写是由单独线程来完成，不影响往缓冲区写map结果的线程。溢写线程启动时不应该阻止map的结果输出，所以整个缓冲区有个溢写的比例 spill.percent。这个比例默认是0.8，也就是当缓冲区的数据已经达到阈值（buffer size * spill.percent = 100MB * 0.8 = 80MB），溢写线程启动，锁定这80MB的内存，执行溢写过程。Map
      task的输出结果还可以往剩下的20MB内存中写，互不影响。

6. 当溢写线程启动后，需要对这80MB空间内的key做排序(Sort)。排序是MapReduce模型默认的行为!

  - 如果job设置过Combiner，那么现在就是使用Combiner的时候了。将有相同key的key/value对的 value加起来，减少溢写到磁盘的数据量。Combiner会优化MapReduce的中间结果，所以它在整个模型中会多次使用。
  - 那哪些场景才能使用Combiner呢？从这里分析，Combiner的输出是Reducer的输入，Combiner 绝不能改变最终的计算结果。Combiner只应该用于那种Reduce的输入key/value与输出 key/value 类型完全一致，且不影响最终结果的场景。比如累加，最大值等。Combiner的使用一定得慎重，如果用好，它对job执行效率有帮助，反之会影响reduce的最终结果。

7. 合并溢写文件：每次溢写会在磁盘上生成一个临时文件（写之前判断是否有combiner），如果 map的输出结果真的很大，有多次这样的溢写发生，磁盘上相应的就会有多个临时文件存在。当整个数据处理结束之后开始对磁盘中的临时文件进行merge合并，因为最终的文件只有一个，写入磁盘，并且为这个文件提供了一个索引文件，以记录每个reduce对应数据的偏移量。至此map整个阶段结束!

**ReduceTask 阶段**

**Reduce大致分为copy、sort、reduce三个阶段，重点在前两个阶段。copy阶段包含一个eventFetcher来获取已完成的map列表，由Fetcher线程去copy数据，在此过程中会启动两个merge线程，分别为inMemoryMerger和onDiskMerger，分别将内存中的数据merge到磁盘和将磁盘中的数据进行merge。待数据copy完成之后，copy阶段就完成了，开始进行sort阶段，sort阶段主要是执行finalMerge操作，纯粹的sort阶段，完成之后就是reduce阶段，调用用户定义的reduce函数进行处理。**

详细步骤

- Copy阶段，简单地拉取数据。Reduce进程启动一些数据copy线程(Fetcher)，通过HTTP方式请求maptask获取属于自己的文件。

- Merge阶段。这里的merge如map端的merge动作，只是数组中存放的是不同map端copy来的数值。Copy过来的数据会先放入内存缓冲区中，这里的缓冲区大小要比map端的更为灵活。

    merge有三种形式：

    - 内存到内存；
    - 内存到磁盘；
    - 磁盘到磁盘。

    默认情况下第一种形式不启用。当内存中的数据量到达一定阈值，就启动内存到磁盘的merge。与map 端类似，这也是溢写的过程，这个过程中如果你设置有Combiner，也是会启用的，然后在磁盘中生成了众多的溢写文件。第二种merge方式一直在运行，直到没有map端的数据时才结束，然后启动第三种磁盘到磁盘的merge方式生成最终的文件。

- 合并排序。把分散的数据合并成一个大的数据后，还会再对合并后的数据排序。
    对排序后的键值对调用reduce方法，键相等的键值对调用一次reduce方法，每次调用会产生零个
    或者多个键值对，最后把这些输出的键值对写入到HDFS文件中。





##### 4. 作业调优检查

配置调优

- map 端的调优属性

| 属性名称                            | 类型    | 默认值                                     | 说明                                                         |
| ----------------------------------- | ------- | ------------------------------------------ | ------------------------------------------------------------ |
| mapreduce.task.io.sort.mb           | int     | 100                                        | 排序 map 输出时所使用的内存缓冲区的大小, 以 MB 作为单位      |
| mapreduce.map.sort.spill.percent    | float   | 0.80                                       | map 输出内存缓存和用来开始磁盘溢出写过程的记录边界索引, 这两者使用的比例的阈值 |
| mapreduce.task.io.sort.factor       | int     | 10                                         | 排序文件时, 一次最多合并的流数, 这个属性也在 reduce 中使用, 将此值增加到 100 是很常见的 |
| mapreduce.map.conbine.minspills     | int     | 3                                          | 运行 combine 所需的最少溢出文件数 (如果已指定 combiner)      |
| mapreduce.map.output.compress       | boolean | false                                      | 是否压缩 map 输出                                            |
| mapreduce.map.output.compress.codec | Class   | org.apache.hadoop.io.compress.DefaultCodec | 用于 map 输出的压缩编解码器                                  |
| mapreduce.shuffle.max.threads       | int     | 0                                          | 每个节点管理器的工作线程数, 用于将 map 输出到 reducer. 这是集群范围的设置, 不能由单个作业设置. 0 表示使用 Netty 默认值, 即两倍可用的处理器数. |

1. 总的原则是给 shuffle 过程尽量多提供内存空间
2. 在 map 端, 可以通过避免多长溢出写磁盘来获得最佳性能, 一次是最佳的情况.



- reduce 端的调优属性



| 属性名称                                      | 类型  | 默认值 | 描述                                                         |
| --------------------------------------------- | ----- | ------ | ------------------------------------------------------------ |
| mapreduce.reduce.shuffle.parallelcopies       | int   | 5      | 用于把 map 输出复制到 reducer 的线程数                       |
| mapreduce.reduce.shuffle.maxfetchfailures     | int   | 10     | 在声明失败之前, reducer 获取一个 map 输出所花的最大时间      |
| mapreduce.task.io.sort.factor                 | int   | 10     | 排序文件时一次最多合并的流的数量, 这个属性也在 map 端使用    |
| mapreduce.reduce.shuffle.input.buffer.percent | float | 0.70   | 在 shuffle 的复制阶段, 分配给 map 输出的缓冲区占堆空间的百分比 |
| mapreduce.reduce.shuffle.merge.percent        | float | 0.66   | map 输出缓冲区 (由 mapred.job.shuffle.input.buffer.percent 定义) 的阈值使用比例, 用于启动合并输出和磁盘溢出写的过程 |
| mapreduce.reduce.merge.inmem.threshold        | int   | 1000   | 启动合并输出和磁盘溢出写过程的 map 输出阈值数. 0 或者更小表示没有阈值限制, 溢出写行为由 mapreduce.reduce.shuffle.merge.percent 单独控制 |
| mapreduce.reduce.input.buffer.percent         | float | 0.0    | 在 reduce 过程中, 在内存中保存 map 输出的空间占整个堆空间的比例. reduce 阶段开始时, 内存中的 map 输出大小不能大于这个值. 默认情况下, 在 reduce 任务开始之前, 所有的 map 输出都合并到磁盘上, 以便为 reducer 提供尽可能的内存. 然而, 如果 reducer 需要的内存较少, 可以增加此值来最小化磁盘访问次数. |



- 作业调优实践

| 范围           | 最佳实践                                                     |
| -------------- | ------------------------------------------------------------ |
| mapper 的数量  | mapper 需要运行多长时间?如果平均只运行几秒钟,则可以看是否能用更少的 mapper 运行更长的时间, <br />通常是一分钟左右,时间长度取决于使用的输入格式 |
| reducer 的数量 | 检查使用的 reducer 数量是不是不超过一个. 根据经验, Reduce 任务应运行 5 分钟左右, 且能产生至少<br />一个数据块的数据 |
| combiner       | 作业能否充分利用 combiner 来减少通过 shuffle 传输的数据量    |
| 中间值的压缩   | 对 map 输出进行压缩几乎总能使作业执行得更快                  |
| 自定义序列     | 如果使用自定义的 Writable 对象或自定义的 comparator, 则必须确保已实现 RawComparator |
| 调整 shuffle   | MapReduce 的 shuffle 过程可以对一些内存管理的参数进行调整, 以弥补性能的不足 |



##### 5. MapReduce 编码

1. 输入格式

- InputFormat
    - FileInputFormat
        - CombineInputFormat
        - TextInputFormat
        - KeyValueTextInputFormat
        - NLineInputFormat
        - SequenceFileInputFormat
            - SequenceFileAsBinaryInputFormat
            - SequenceFileAsTextInputFormat
            - SequenceFileInputFilter
    - ComposableInputFormat
        - CompositeInputFormat
    - DBInputFormat

FileInputFormat 是所有使用文件作为其数据源的 InputFormat 实现的基类. 它提供两个功能: 

- 用于指出作为的输入文件位置
- 为输入文件生成分片的代码实现



2. 输出格式

- OutputFormat

    - FileOutputFormat
        - TextOutputFormat
        - SequenceFileOutputFormat
            - SequenceFileAsBinaryOutputFormat
    - NullOutputFormat
    - DBOutputFormat
    - FilterOutputFormat
        - LazyOutputFormat

- MultipleOutputFormat

    可以将数据写到多个文件中, 这些文件的名称源于输出的键和值或者任意字符串.

